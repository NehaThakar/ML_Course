{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Image Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Folder to store images\n",
    "\n",
    "def make_target_folder(query_string: str):\n",
    "    target_path = '.\\images'\n",
    "    target_folder = os.path.join(target_path, '_'.join(query_string.lower().split(\" \")))\n",
    "    \n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "        \n",
    "    return target_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the web page, listing all the thumbnails in the page and extracting the urls for the specified number of images\n",
    "\n",
    "def extract_image_urls(query: str, max_links: int,wd: webdriver):\n",
    "    \n",
    "    #def scroll_to_end(wd):\n",
    "    wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "        \n",
    "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\n",
    "    wd.get(search_url.format(q=query))\n",
    "    \n",
    "    image_urls = set()\n",
    "    image_count = 0\n",
    "    results_start = 0\n",
    "    while image_count < max_links:\n",
    "#         scroll_to_end(wd)\n",
    "        \n",
    "        thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\n",
    "        number_results = len(thumbnail_results)\n",
    "\n",
    "        print(f\"There are {number_results} thumb nails. Extracting links from {results_start}: {number_results} \")\n",
    "\n",
    "        for image in thumbnail_results[results_start:number_results]:\n",
    "\n",
    "            try:\n",
    "                image.click()\n",
    "                #time.sleep(1)\n",
    "            except:\n",
    "                print(\"Could not collect information... Moving to next.....\")\n",
    "                continue\n",
    "\n",
    "            actual_images = wd.find_elements_by_css_selector(\"img.n3VNCb\")\n",
    "\n",
    "            for actual_image in actual_images:\n",
    "                if (actual_image.get_attribute('src')) and ('http' in actual_image.get_attribute('src')):\n",
    "                    image_urls.add(actual_image.get_attribute('src'))\n",
    "\n",
    "            if len(image_urls) >= max_links:\n",
    "                print(f\"Found: {len(image_urls)} links... Done!....\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Found: {len(image_urls)} links...Looking for more, please wait......\")\n",
    "                #time.sleep(2)\n",
    "                \n",
    "#         load_more_button = wd.find_element_by_css_selector(\".mye4qd\")\n",
    "#         if load_more_button:\n",
    "#             wd.execute_script(\"document.querySelector('.mye4qd').click();\")\n",
    "                \n",
    "        results_start = len(thumbnail_results)\n",
    "        image_count = len(image_urls)\n",
    "            \n",
    "    return image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the images and store using the extracted urls from the previous step\n",
    "\n",
    "def download_image(url, folder_path, counter):\n",
    "    \n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "    except Exception as e:\n",
    "        print(\"Unable to download the image...\")\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        file_location = os.path.join(folder_path,\"jpg\" + \"_\" + str(counter) + \".jpg\")\n",
    "        #print(file_location)\n",
    "        f = open(file_location, 'wb')\n",
    "        f.write(image_content)\n",
    "        f.close()\n",
    "        #print(f\"Saved the as {file_location}\")\n",
    "    except Exception as e:\n",
    "        print(\" Could not save the content.....\", e)\n",
    "        \n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function which peforms the complete opertion with the help of other defined functions\n",
    "\n",
    "def search_download(query_string, driver_path):\n",
    "    folder_path = make_target_folder(query_string)\n",
    "    \n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\n",
    "        urls = extract_image_urls(query_string, 10, wd=wd)\n",
    "    \n",
    "    counter = 1\n",
    "    for url in urls:\n",
    "        download_image(url,folder_path,counter)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48 thumb nails. Extracting links from 0: 48 \n",
      "Found: 0 links...Looking for more, please wait......\n",
      "Found: 0 links...Looking for more, please wait......\n",
      "Found: 0 links...Looking for more, please wait......\n",
      "Found: 1 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 3 links...Looking for more, please wait......\n",
      "Found: 4 links...Looking for more, please wait......\n",
      "Found: 5 links...Looking for more, please wait......\n",
      "Found: 6 links...Looking for more, please wait......\n",
      "Found: 7 links...Looking for more, please wait......\n",
      "Found: 7 links...Looking for more, please wait......\n",
      "Found: 8 links...Looking for more, please wait......\n",
      "Found: 9 links...Looking for more, please wait......\n",
      "Found: 10 links... Done!....\n"
     ]
    }
   ],
   "source": [
    "## Specifying the driver path and initializing the complete image scrapping process\n",
    "\n",
    "query_string = 'apple'\n",
    "driver_path ='./chromedriver'\n",
    "search_download(query_string, driver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48 thumb nails. Extracting links from 0: 48 \n",
      "Found: 0 links...Looking for more, please wait......\n",
      "Found: 1 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Could not collect information... Moving to next.....\n",
      "Found: 2 links...Looking for more, please wait......\n",
      "Found: 3 links...Looking for more, please wait......\n",
      "Found: 4 links...Looking for more, please wait......\n",
      "Found: 4 links...Looking for more, please wait......\n",
      "Found: 4 links...Looking for more, please wait......\n",
      "Found: 5 links...Looking for more, please wait......\n",
      "Found: 6 links...Looking for more, please wait......\n",
      "Found: 7 links...Looking for more, please wait......\n",
      "Found: 7 links...Looking for more, please wait......\n",
      "Found: 8 links...Looking for more, please wait......\n",
      "Found: 9 links...Looking for more, please wait......\n",
      "Found: 9 links...Looking for more, please wait......\n",
      "Found: 11 links... Done!....\n"
     ]
    }
   ],
   "source": [
    "## Querying for 'iphone' images\n",
    "query_string = 'iphone'\n",
    "driver_path ='./chromedriver'\n",
    "search_download(query_string, driver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
